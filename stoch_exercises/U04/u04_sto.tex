\documentclass[a4paper]{article}

% --- DATA ---

\def\lecture{Stochastik 2}
\def\authors{Linus Mußmächer}
\def\sheetNumber{04}
%\def\sumPoints{30} 

% --- PREAMBLE ---

\usepackage[german]{babel}	% language specific quotation marks etc.
\input{../../preambles/exercise_preamble.tex}

% --- DOCUMENT ---

\begin{document}

\makeexheaderger

\subsection{Zentralübung}

Ein Varianz-Kovarianzmatrix muss positiv definit sein. Gilt $|\rho| \leq 1$, so ist
\begin{equation*}
    2 \geq 0 \qquad 2 - \rho^2 \geq 0 \qquad 4 - 4 \rho^2 \geq 0
\end{equation*}
und $\Sigma$ nach dem Hurwitz-Kriterium positiv definit.
Nach der Varianz-Kovarianz-Formel ist 
\begin{equation*}
    \mathrm{Var}[X_1 + X_2 + X_3 = \sum_{i = 1}^3 \mathrm{Var}[X_i] +  \sum_{1 \leq i < j \leq 3} 2 \mathrm{Cov}(X_i, X_j)= \sum_{i=1}^{3} \Sigma_{ii} + \sum_{1 \leq i < j \leq 3} 2 \cdot \Sigma_{ij} = 5 + 8 \rho\text{.}
\end{equation*}
Weiterhin ist die Kovarianz der Zufallsvariablen $X_1, -X_2, -X_3$ wegen der Bilinearität der Kovarianz gleich
\begin{equation*}
    \Sigma' = \left(\begin{matrix}
        2 & - \rho & 0 \\ - \rho & 1 & \rho \\ 0 & \rho & 2
    \end{matrix}\right)
\end{equation*}
und somit gilt erneut mit der Varianz-Kovarianz-Formel
\begin{equation*}
    \mathrm{Var}[X_1 - X_2 - X_3 =  \sum_{i=1}^{3} \Sigma'_{ii} + \sum_{1 \leq i < j \leq 3} 2 \cdot \Sigma'_{ij} = 5 \text{.}
\end{equation*}
Setzen wir $Y_1 = X_1 + X_2 + X_3$ sowie $Y_2 = X_1 - X_2 - X_3$, so gilt 
\begin{equation*}
    \mathrm{Var}(Y_1 + Y_2) = \mathrm{Var}(Y_1) + \mathrm{Var}(Y_2) + \mathrm{Cov}(Y_1, Y_2)
\end{equation*}
unter Verwendung von $\mathrm{Var}(Y_1 + Y_2) = \mathrm{Var}(2 X_1) = 4 \cdot \mathrm{Var}(X_1) = 8$ folgt damit
\begin{equation*}
    \mathrm{Cov}(Y_1, Y_2) = \mathrm{Var}(Y_1 + Y_2) - \mathrm{Var}(Y_1) - \mathrm{Var}(Y_2) = 8 - (5 - 8 \rho) - 5 = -2 + 8 \rho
\end{equation*}
und damit sind $Y_1, Y_2$ genau für $\rho = \frac{1}{4}$ (mit $|\rho| < 1$) unkorreliert.

\subsection{}

\begin{enumerate}
    \item Wir erhalten die Marginalverteilungen durch Addition über die Reihen/Spalten der Tabelle der gemeinsamen Verteilung:
    \begin{center}
        \begin{tabular}{|c|c|}
            \hline
            X & $\Sigma$ \\ \hline
            -1 & $\frac{3}{8}$ \\ \hline
            0 & $\frac{1}{4}$ \\ \hline
            1 & $\frac{1}{4}$ \\ \hline            
        \end{tabular}\qquad
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            Y & -2 & -1 & 1 & 2 \\ \hline
            $\Sigma$ & $\frac{3}{16}$ & $\frac{5}{16}$ & $\frac{5}{16}$ & $\frac{3}{16}$ \\ \hline
        \end{tabular}
    \end{center}
    \item Wir bestimmen zuerst die Verteilung von $X \cdot Y$:
    \begin{align*}
        P(X \cdot Y = -2) &= P(X = 1, Y = -2) + P(X = -1, Y = 2) = \frac{1}{16} + \frac{1}{16} = \frac{1}{8}\\
        P(X \cdot Y = -1) &= P(X = 1, Y = -1) + P(X = -1, Y = 1) = \frac{1}{8} + \frac{1}{8} = \frac{1}{4}\\
        P(X \cdot Y = 0) &= P(X = 0) = \frac{1}{4}\\
        P(X \cdot Y = 1) &= P(X = 1, Y = 1) + P(X = -1, Y = -1) = \frac{1}{8} + \frac{1}{8} = \frac{1}{4}\\
        P(X \cdot Y = 2) &= P(X = 2, Y = -1) + P(X = -1, Y = 2) = \frac{1}{16} + \frac{1}{16} = \frac{1}{8}\text{.}
    \end{align*}
    Aus der Symmetrie folgern wir $\mathds{E}[X\cdot Y] = 0$, aus den obigen (ebenfalls symmetrischen) Verteilungen analog $\mathds{E}[X] = \mathds{E}[Y] = 0$. Dies zeigt
    \begin{equation*}
        \mathrm{Cov}(X,Y) = \mathds{E}[X \cdot Y] - \mathds{E}[X] \cdot \mathds{E}[Y] = 0 - 0 \cdot 0 = 0 
    \end{equation*}
    \item Die beiden Variablen sind unkorreliert, aber wegen 
    \begin{align*}
        P(Y = 1 \mid X = 0) &= \frac{P(Y = 1, X = 0)}{P(X = 0)} = \frac{\frac
        {1}{16}}{\frac{4}{16}} = \frac{1}{4}\\
        P(Y = 1 \mid X = 1) &= \frac{P(Y = 1, X = 1)}{P(X=1)} = \frac{\frac{1}{8}}{\frac{3}{8}} = \frac{1}{3} 
    \end{align*} nicht unabhängig.
\end{enumerate}

\subsection{}

\begin{enumerate}
    \item Wir berechnen das Integral über $f_Z$:
    \begin{align*}
        \int_\mathds{R} \int_\mathds{R} f_Z(x,y) dy dx &= \int_1^2 \frac{2}{3} \int_{0}^{\infty}  x^2 \exp(-xy) dy dx\\
        &= \frac{2}{3} \int_{1}^{2} x^2 \left[ \frac{1}{-x} \exp(-xy) \right]_0^\infty dx\\
        &= \frac{2}{3} \int_{1}^{2} - x (\underbrace{0}_{\mathclap{\text{da }x>0}} - 1) dx = \frac{2}{3} \int_{1}^{2} x dx \\
        &= \frac{2}{3} \left[\frac{x^2}{2}\right]_1^2 = \frac{2}{3} \left(\frac{4}{2} - \frac{1}{2}\right) = \frac{2}{3} \cdot \frac{3}{2} = 1\text{.}
    \end{align*}
    und somit handelt es sich bei $f_Z$ um eine Verteilungsfunktion.
    \item Wir berechnen zuerst für $t \in [1,2]$:
    \begin{align*}
        F_X(t) &= P(X \leq t) = \int_1^t \int_{0}^{\infty} f_Z(x,y) dy dx \\
        &= \mathds{1}_{t \in [1,2]} \frac{2}{3} \int_{1}^{t} x dx = \frac{t^2 - 1}{3}\text{.}
    \end{align*}
    Dies zeigt
    \begin{equation*}
        F_X(t) = \left\{ \begin{matrix}
            0 & t < 1\\ \frac{t^2 - 1}{3} & t \in [1,2] \\ 1 & t > 2
        \end{matrix} \right. \text{.}
    \end{equation*}
    Analog betrachten wir $Y$ für $t > 0$ (da der Fall $t = 0$ als Nullmenge vernachlässigt werden darf):
    \begin{align*}
        F_Y(t) &= P(Y \leq t) = \int_{1}^{2} \int_{0}^{t} f_Z(x,y) dy dx = \frac{2}{3} \int_{1}^{2} x^2 \frac{1}{-x} \left[ \exp(-xy) \ \right]_0^t dx \\
        &= \frac{2}{3} \int_{1}^{2} - x \left( \exp(-xt) - 1 \right) = \frac{2}{3} \int_1^2 x dx - \frac{2}{3} \int_1^2 x \exp(-x t) dx \\
        &= 1 - \frac{2}{3} \left[ - \frac{x}{t} \exp(-xt) - \frac{1}{t^2} \exp(-xt) \right]_1^2 \\
        &= 1 - \frac{2}{3} \left( \frac{t+1}{t^2} \exp(-t) - \frac{2t + 1}{t^2} \exp(-2t) \right)
    \end{align*}
    \item 
    % Wir bestimmen die marginale Verteilung von $X$, indem wir für festes $x \in [1,2]$ über alle möglichen Werte von $Y$ integrieren.
    % \begin{align*}
    %     f_X(x) &= \int_{\mathds{R}} f_Z(x,y) dy = \frac{2}{3} x^2 \int_{0}^{\infty} \exp(-xy) dy \\
    %     &= \frac{2}{3} x^2 \cdot \frac{1}{-x} \cdot (0-1) = \frac{2}{3} x
    % \end{align*}
    % für $x \in [1,2]$ und $P(X = x) = 0$ sonst. Für $Y$ gehen wir analog vor:
    % \begin{align*}
    %     f_Y(y) &= \int_{\mathds{R}} f_Z(x,y) dx = \frac{2}{3} \int_{1}^{2} x^2 \exp(-xy) dx \\
    %     &= \frac{2}{3} \left[ -\frac{x^2}{y} \exp(-xy) - \frac{2x}{y^2} \exp(-xy) - \frac{2}{y^3} \exp(-xy)  \right]_1^2\\
    %     &= \frac{2}{3} \left( - \left(\frac{4}{y} + \frac{4}{y^2} + \frac{2}{y^3}  \right) \exp(-2y) + \left( \frac{1}{y} + \frac{2}{y^2} + \frac{2}{y^3} \right) \exp(-y) \right) \\
    %     &= \frac{2}{3} \left( \frac{y^2 + 2y + 2}{y^3} \exp(-y) - \frac{4y^2 + 4y + 2}{y^3} \exp(-2y) \right)
    % \end{align*}
\end{enumerate}

\subsection{}
\begin{enumerate}
    \item Kontigenztafel:
    \begin{center}
        \begin{tabular}{|c|c|c|c|c|c|c|c|}
            \hline
            M  S & 0 & 1 & 2 & 3 & 4 & 5 & $\Sigma$ \\ \hline
            0 & $\frac{1}{8}$ & 0 & 0 & 0 & 0 & 0 & $\frac{1}{8}$ \\ \hline
            1 & 0 & $\frac{1}{8}$ & 0 & 0 & 0 & 0 & $\frac{1}{8}$ \\ \hline
            2 & 0 & 0 & $\frac{2}{8}$ & $\frac{2}{8}$ & $\frac{1}{8}$ & $\frac{1}{8}$ & $\frac{3}{4}$\\ \hline
            $\Sigma$ & $\frac{1}{8}$ & $\frac{1}{8}$ & $\frac{2}{8}$ & $\frac{2}{8}$ & $\frac{1}{8}$ & $\frac{1}{8}$ &  1 \\ \hline
        \end{tabular}
    \end{center}
    \item Die beiden Zufallsvariablen sind nicht unabhängig, denn es ist 
    \begin{equation*}
        P(S = 0 \mid M = 0) = 1 \neq 0 = P(S = 0 \mid M = 1) \text{.}
    \end{equation*}
\end{enumerate}



\end{document}























