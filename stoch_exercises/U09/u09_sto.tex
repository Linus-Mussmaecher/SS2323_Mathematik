\documentclass[a4paper]{article}

% --- DATA ---

\def\lecture{Stochastik 2}
\def\authors{Linus Mußmächer}
\def\sheetNumber{09}
%\def\sumPoints{30} 

% --- PREAMBLE ---

\usepackage[german]{babel}	% language specific quotation marks etc.
\input{../../preambles/exercise_preamble.tex}

% --- DOCUMENT ---

\begin{document}

\makeexheader

\subsection{Zentralübung}


\begin{enumerate}
    \item Es ist $(X_i)$ gleichgradig integrierbar, d.h. es ist 
    \begin{equation*}
        \lim_{n \to \infty} \sup_{i \in I} \int_{\{|X_i| \geq n\}} |X_i| d \mathds{P} = 0\text{.}
    \end{equation*}
    Insbesondere existiert ein $N \in \mathds{N}$ mit $\int_{\{|X_i| \geq n\}} |X_i| d \mathds{P} < 1$ für alle $i \in I$ und damit ist
    \begin{equation*}
        \mathds{E}[|X_i|] = \int |X_i| d \mathds{P} = \int_{\{|X_i| \geq n\}} |X_i| d \mathds{P} + \int_{\{|X_i| < n\}} |X_i| d\mathds{P} < 1 + n 
    \end{equation*}
    für alle $i \in I$. Sei nun $\epsilon > 0$ beliebig.
    Dann existiert folglich ein $r > 0$ mit $\frac{1}{r} \mathds{E}[|X_i|] < \epsilon$ für alle $i \in I$ und damit
    \begin{equation*}
        \mathds{P}(X_i \notin \closure{K_r(0)}) = \mathds{P}(|X_i| > r) \leq \frac{1}{r} \mathds{E}[|X_i|] \leq \frac{1}{r} \mathds{E}[|X_i|] < \epsilon
    \end{equation*}
    und damit $\mathds{P}(X_i \in \closure{K_r(0)}) \geq 1 - \epsilon$. Da $\closure{K_r(0)}$ kompakt ist, zeigt dies die Straffheit.
    \item Betrachte die Familie $(X_n)_{n \in \mathds{N}}$ mit $X_n = n \cdot \mathds{1}_{[0, 1/n]}$ (wobei $\mathds{P}$ der uniformen Verteilung auf $[0,1]$ entspreche). 
    Dann ist $X_n$ straff, denn für die kompakte Menge $[0,1]$ gilt $\mathds{P}(X_n \in [0,1]) = 1 \geq 1 - \epsilon$ für alle $\epsilon > 0$. 
    Allerdings ist $(X_n)$ nicht uniform integrierbar, denn für beliebiges $N \in \mathds{N}$ ist $\int_{|X_{N}| \geq N} |X_N| d \mathds{P} = N \cdot \frac{1}{N} = 1$, also $\sup_{n \in \mathds{N}}  \int_{|X_{n}| \geq N} |X_n| d \mathds{P} \geq 1$.
    Somit kann der Limes $n \to \infty$ auch nur größer oder gleich $1$ sein und es $(X_n)$ ist nicht uniform integrierbar.
\end{enumerate}


\subsection{}

%(b) wichtig

\subsection{}

%(d) ist äquivalent, aber muss nicht gezeigt werden

\subsection{}


\begin{enumerate}
    \item Die Wahrscheinlichkeitsfunktionen zu $X$ bzw. $X_n$ sind
    \begin{equation*}
        F(k) = \exp(- \lambda) \frac{\lambda^k}{k!} \qquad F_n(k) = \binom{n}{k} \left(\frac{\lambda}{n}\right)^{k} \left(1 - \frac{\lambda}{n}\right)^{n-k} \text{.}
    \end{equation*}
    Dann gilt
    \begin{align*}
        F_n(k) &= \frac{n!}{k!(n-k)!}  \left(\frac{\lambda}{n}\right)^{k} \left(1 - \frac{\lambda}{n}\right)^{n-k} \\
        &= \frac{n!}{(n-k)! \cdot n^k}  \frac{\lambda^k}{k!} \left(1 - \frac{\lambda}{n}\right)^n \cdot \left(1 - \frac{\lambda}{n}\right)^{-k}\\
        &= \left(\prod_{m=n-k+1}^{n} \underbrace{\frac{m}{n}}_{\to 1}\right) \cdot \frac{\lambda^k}{k!} \underbrace{\left(1 + \frac{-\lambda}{n}\right)^n}_{\to \exp(-\lambda)} \cdot \underbrace{\left(1 - \frac{\lambda}{n}\right)^{-k}}_{\to 1}\\
        &\to \frac{\lambda^k}{k!} \exp(-\lambda) = F(k)\text{.}
    \end{align*}
    Man beachte insbesondere, dass das Produkt stets eine feste Anzahl an Faktoren hat, die einzeln gegen $1$ konvergieren, wenn $n$ und damit auch $m$ gegen $\infty$ strebt. Da die Verteilungsfunktionen von $X$ bzw. $X_n$ jeweils nur aus Summen der obigen Terme bestehen und diese Summen daher summandenweise konvergieren, konvergieren auch die Verteilungsfunktionen punktweise. Dies zeigt $X_n \to X$.
    \item Wir wissen, dass die Summe unabhängiger Poisson-verteilter Zufallsvariablen wiederum Poisson-verteilt ist.
    Daher gilt $\tilde{X}_n \coloneq \sum_{i = 1}^{n} X_i \sim \mathrm{Poiss}(\lambda \cdot n)$.
    Wir bezeichnen im Folgenden die Verteilungsfunktion dieser Summe mit $\tilde{F}_n$.
    Dann ist für $x \geq 0$:
    \begin{align*}
        \tilde{F}_n(\log_{1 + 1/n}(x)) &= \mathds{P}(\tilde{X}_n < \log_{1 + 1/n}(x)) = \sum_{k = 0}^{\log_{1 + 1/n}(x)} \mathds{P}(\tilde{X}_n = k) \\
        &= \sum_{k = 0}^{\log_{1 + 1/n}(x)} \frac{n^k \lambda^k}{k!} \exp(- \lambda n) = \exp(- \lambda n) x^n = \left( e^{-\lambda} x \right)^n \\
        &\to \left\{ \begin{matrix}
            1 & x \geq e^\lambda \\ 0 & x < e^\lambda 
        \end{matrix}\right. = \mathds{1}_{[e^\lambda, \infty)}
    \end{align*}

    Sei nun $F_n$ die Verteilungsfunktion von $Y_n$, die Verteilungsfunktion von $e^\lambda$ ist $F = \mathds{1}_{[e^\lambda, \infty)}$ und ist stetig für alle $x \in \mathds{R}$ außer $e^\lambda$.

    Sei $x \in \mathds{R}$ beliebig.
    Falls $x < 0$, so ist $F_n(x) = 0 = F(x)$ für alle $n$.
    Sei daher $x \in [0, \infty)$ und sei $\epsilon > 0$ beliebig.
    Dann gilt:
    \begin{align*}
        F_n(x) = \mathds{P}(Y_n < x) = \mathds{P}\left(\sum_{i = 1}^{n} X_i < \log_{1+1/n} x\right) = \tilde{P_n}(\log_{1 + 1/n}(x)) \to \mathds{1}_{[e^\lambda, \infty)}
    \end{align*}
    d.h. $Y_n$ konvergiert schwach gegen $e^\lambda$.
    Satz 3.20 zeigt nun, dass $Y_n$ auch stochastisch gegen $e^\lambda$ konvergiert.
\end{enumerate}

\end{document}